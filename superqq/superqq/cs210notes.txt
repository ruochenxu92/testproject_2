CS210: ----------------------------------------------------------------------------------- W2 CS210: Philosophical Ethics CS210 Spring 2015 Week 2 Announcements @ First wri?en assignment has been posted – Due on Monday (11:59pm) – NO LATE ASSIGNMENTS – Submit via SVN – MUST be PDF – MUST not have idenQfying informaQon Review @ What did we discuss last week? White Rose Morality @ System of rules for guiding human conduct @ Two kinds of rules: – DirecQves: for individuals (microethics) – Social polices: for society (macroethics) @ System of principles for evaluaQng those rules @ Purpose: prevent or alleviate harm and suffering (and possibly promote human flourishing) Moral System @ Public: everyone knows the rules @ Informal: not enforced by law @ RaQonal: based on principles of logic and reason understood by all moral agents @ ImparQal: moral rules are designed to apply equitably to all parQcipants Ethics @ The study of moral issues @ Moral principles derived from and grounded in philosophy @ Theories tested using logical argumentaQon @ Remain open to different sides of a dispute Cyberethics @ The study of moral, legal, and social issues involving cybertechnology @ cyber = computers + communicaQons Three Cases 1. Amanda Todd 2. Sony Hack 3. BitCoin Is “Cyberethics” Really a Thing? @ Are there new and unique moral problems? @ Unique feature or unique issue? Policy Vacuum @ Technology developed before policies are put in place – “policies” include laws and social norms @ “Conceptual muddles” Four Phases of Cyberethics Phase Time Period Technological Features Associated Issues 1 1950’s - 1960’s Stand-alone machines (mainframes) ArQficial intelligence Database privacy 2 1970’s - 1980’s LANs/WANs Desktop computers Intellectual property Sohware piracy Computer crime CommunicaQon privacy 3 1990’s - present Internet Social media Mobile compuQng Free speech Anonymity Legal jurisdicQon Virtual communiQes 4 Present to near future Converging technologies Autonomous drones NanocompuQng Ubiquitous compuQng Applied Ethics @ ExaminaQon of pracQcal moral issues @ Use philosophical ethics in analysis @ Three perspecQves of study 1. Professional 2. Philosophical 3. Sociological 1. Professional @ How we should behave as CS professionals @ Like lawyers, doctors, and civil engineers, we should have professional standards 2. Philosophical @ Considers broader moral concerns @ Standard methodology for research 3. Sociological @ Previous perspecQves were norma3ve @ Sociology is descrip3ve Disclosive Model @ Combine professional, philosophical and sociological approaches @ Need “disclosive” method @ IdenQfy “morally opaque” features @ “morally opaque” features can be unknowable to users Disclosive Model @ Levels of analysis 1. Disclosure - Computer Science and Social Science 2. TheoreQcal - Philosophy 3. ApplicaQon - Computer Science Social Science Philosophy Comprehensive Method 1. Iden3fy the pracQce or feature a. Disclose opaque features b. Assess sociological implicaQons c. Search for exisQng policies or ethical codes 2. Analyze the ethical issue a. Iden3fy any policy vacuums b. Clear up conceptual muddles Comprehensive Method 3. Deliberate on the ethical issue a. Apply one or more ethical theories b. Jus3fy the posiQon using logical argumentaQon All our knowledge begins with the senses, proceeds then to the understanding, and ends with reason. There is nothing higher than reason. - Immanuel Kant -------------------------------------------------------------------------------------------------- W3 Ethical Theories CS210 Spring 2015 Week 3 Announcements @ Second wri@en assignment has been posted – Name the file W2.PDF – Due on Monday (11:59pm) – NO LATE ASSIGNMENTS – NO IDENTIFYING INFORMATION Announcements @ Peer review for W1 @ Folder called W1_review – 4 or 5 PDFs with random names – your_reviews.txt @ Read each PDF and review it in the text file @ Follow the rubric on the course website @ Half of evaluaYon score based on similarity to staff scores Review @ What did we discuss last week? Three Cases 1. Amanda Todd 2. Sony Hack 3. BitCoin Comprehensive Method 1. Iden'fy the pracYce or feature a. Disclose opaque features b. Assess sociological implicaYons c. Search for exisYng policies or ethical codes 2. Analyze the ethical issue a. Iden'fy any policy vacuums b. Clear up conceptual muddles Comprehensive Method 3. Deliberate on the ethical issue a. Apply one or more ethical theories b. Jus'fy the posiYon using logical argumentaYon ObjecYons 1. People disagree about morality. 2. Who am I to judge others? 3. Isn’t morality a private ma@er? 4. Isn’t morality determined by culture? 1) People disagree. @ Experts in many fields disagree. @ We agree on many moral issues. @ We can agree on principles while disagreeing about facts. 2) Who am I to judge others? @ We judge people all the Yme. @ We can judge without condemning. @ We are morally obligated to judge others. 3) Morality is a personal choice. @ This is an oxymoron. Morals are public. @ This is moral subjec'vism. 4) Morality is cultural. @ Cultural rela'vism does not imply moral rela'vism. @ Moral absoluYsm vs. moral relaYvism is a false dilemma. @ Ethical objec'vism is another opYon Ethical Theories @ Criteria for an ethical theory: – internally coherent and consistent – comprehensive – systemaYc @ We will learn 4 major theories @ All versions of ethical objecYvism! Ethical Theories 1. Consequence-based 2. Duty-based 3. Contract-based 4. Character-based 1) Consequence-based @ Primary goal of moral system is to produce desirable outcomes for moral agents @ Called u'litarianism Act vs. Rule UYlitarianism @ Act uYlitarianism - ac'ons should lead to greatest happiness @ Rule uYlitarianism - follow rules that lead to greatest happiness 2) Duty-based @ Morality is grounded in moral agents’ obligaYons to one another @ Called deontology Rule vs. Act Deontology @ Rule deontology - make decisions according to fixed objecYve universal rules @ Act deontology - analyze individual situaYon and act according to the most important duty 3) Contract-based @ Morality is grounded in moral agents’ mutual best interests. @ Give up some rights so others do the same. 4) Character-Based @ Morality is grounded in virtues. @ Called virtue or Aristotelian ethics @ Lead to eudaimonia - human flourishing Ethical Theories @ Which should we use? @ All of them. Many of our most serious conflicts are conflicts within ourselves. Those who suppose their judgments are always consistent are unreflec've or dogma'c - John Rawls ----------------------------------------------------------------------------------------- W4 CS210: Logical Argumenta6on CS210 Spring 2015 Week 4 Announcements @ Third wriAen assignment has been posted @ Peer reviews from last week have been posted Review @ What is morality? @ What is ethics? @ What does “morally opaque” mean? @ What is “moral subjec6vism”? @ How does cultural rela6vism differ from moral rela6vism? @ What is moral absolu6sm? Review @ What is ethical objec6vism? @ What were the four ethical theories? @ Can you describe each theory? @ What is eudaimonia? @ What is our comprehensive method for approaching ethical issues? Comprehensive Method 1. Iden-fy the prac6ce or feature a. Disclose opaque features b. Assess sociological implica6ons c. Search for exis6ng policies or ethical codes 2. Analyze the ethical issue a. Iden-fy any policy vacuums b. Clear up conceptual muddles Comprehensive Method 3. Deliberate on the ethical issue a. Apply one or more ethical theories b. Jus-fy the posi6on using logical argumenta6on Logical Argumenta6on @ Method we use to test an ethical thesis @ Claim - a statement or asser6on @ Argument - a series of claims aimed at establishing the truth of one central claim (the conclusion) @ Each of the other claims is called a premise Argument Structure Premise 1 Premise 2 Premise 3 … Premise n ------------------------- Conclusion Argument Structure Classes should teach methods for tes6ng theses. This class is about ethics. Ethical theses are tested by argumenta6on. ---------------------------------------------------- This class should teach logical argumenta6on. Valid arguments @ If we accept the premises, it is impossible for the conclusion to be false. @ An invalid argument is one where we can imagine that the conclusion could be false, even if we accept all of the premises as true. @ One counterexample is sufficient to iden6fy an invalid argument. Example All students who drink coffee are smart. Jamie is a student. Jamie does not drink coffee. ---------------------------------------------------- Jamie is not smart. Example All smart students drink coffee. Jamie is a student. Jamie does not drink coffee. ---------------------------------------------------- Jamie is not smart. Sound arguments @ A valid argument whose premises are all true @ A sound argument is strong Example All CEOs of US companies have been US ci6zens. Marissa Mayer is a US ci6zen. ---------------------------------------------------- Marissa Mayer is a CEO of a US company. Example Most CEOs are college graduates. Satya Nadella is a CEO. ---------------------------------------------------- Satya Nadella is a college graduate. Induc6ve arguments @ Assuming premises are true, conclusion likely follows. @ An invalid argument can be strong if it is induc-ve. Example 90% of iPhone users with a laptop own Apple laptops. I have an iPhone. I have a laptop. ---------------------------------------------------- I own an Apple laptop. Fallacious arguments @ Invalid arguments whose premises do not support their conclusion @ Premises have no bearing on truth of conclusion Example The Internet is a public space. ---------------------------------------------------- Those who use the Internet should not expect privacy. Arguments Valid Invalid Sound Unsound Induc6ve Fallacious Strong Evalua6ng an argument 1. Iden6fy premises and conclusion 2. Test validity (look for counterexample) 3. If valid, check if sound (inves6gate premises) 4. If invalid, check if induc6ve (is conclusion more likely to be true if premises are true?) 5. Assess the argument’s strength From now on… @ Evaluate your peers’ arguments @ Evaluate references’ arguments @ Evaluate my arguments @ Evaluate textbook’s arguments @ Evaluate your own arguments! Tips for making a good argument @ Start with conclusion @ Make a strong argument @ Explain why each premise supports your claim @ An6cipate and respond to counterarguments @ Be charitable to your opponent @ Careful about rhetorical flourishes “I would never die for my beliefs, because I might be wrong.” - Bertrand Russell “Doubt is an uncomfortable condi6on, but certainty is a ridiculous one.” -Voltaire ======================================================================= W5 Review @ What is a valid argument? @ What is a sound argument? @ What is an induc6ve argument? @ What is a fallacious argument? Announcements @ Fourth wri:en assignment has been posted @ Peer reviews from last week have been posted CS210: Fallacies and Biases CS210 Spring 2015 Week 5 FALLACIES Non sequitur @ Conclusion does not follow from premises. @ “It does not follow” @ Examples: You’re a computer science major. You should fix my computer. Kanye West was rude to Beck. His music sucks. Non sequitur @ Appeal to popularity @ Appeal to consequences @ Appeal to emo6on @ Appeal to nature @ Appeal to novelty @ Appeal to tradi6on @ Appeal to authority @ Appeal to threat Fallacy Fallacy @ If the argument contains a fallacy, then the conclusion is false. @ Examples: STRAWMAN! STRAWMAN! Stop strawmanning me! Ad hom! Ad hom! Ad hominem @ A:acking the person instead of their argument @ “To the person” Example: You think the Xbox controller is beHer than the Dual Shock? You’re just an Xbox fanboy. Poisoning the Well @ A preemp6ve ad hominem a:ack Examples: My opponent is a communist. Don’t listen to them. Only a terrorist would want to lower the military budget. Tu quoque @ Appealing to hypocrisy (ad hominem) @ “you also” Example: How can you argue stealing is wrong, thief? Of course one of the reasons that some of the media have picked up on FinFisher products and make such a fuss is that some of them… have been shown in the past to be by their own admission guilty of the most appalling breaches. Appeal to Authority @ Inverted ad hominem. Because an authority agrees with your posi6on, it is true. @ Example: 100 scienSsts agree that cigareHes don’t cause cancer. Strawman @ A:acking an ar6ficial or weak argument instead of your opponent’s actual argument @ Listen for phrase “So you’re saying…” @ Example: "So don't get the wrong idea," he wants to say to us, “Yeah, I'm asking Congress for permission to go kick buH, but don't think that's what we're doing.” Equivoca6on @ Using ambiguity of meaning to mislead. @ Examples: I have the right to make money, therefore making money is right. Nothing is beHer than being happy. Having $2 is beHer than nothing. Having $2 is beHer than being happy. Argument from Ignorance @ You can’t prove me wrong, therefore I am right. Example: We can’t understand how crop circles are formed with such complex paHerns, therefore they must be made by aliens. Name that fallacy! @ I see miracles everyday Oceans spanning beyond my sight And a million stars way above em at night @ If Europe’s health care system is so great, why don’t you move there? @ Nobody can prove that there is not between the Earth and Mars a china teapot revolving in an ellipScal orbit. Complex Ques6on @ S6cking a presupposi6on into a ques6on. Examples: How o]en do you beat your wife? How can you support this tax? Don’t you believe in freedom? Begging the Ques6on @ Assuming the conclusion in your argument. Example: There is no god but Allah, and Muhammad is his prophet. Let’s assume for the sake of argument that your God is the one true God. That would mean Allah is not the one true God. Which we know he is. Don’t you see your logic eats itself! False Dilemma @ Two op6ons are presented as the only choices, but others are possible Examples: America must cut military spending or we will go into debt. If we reject moral relaSvism, we must accept moral absoluSsm. Argument to Modera6on @ Assuming the middle of two posi6ons is correct @ Examples Some people think vaccines cause auSsm. Others disagree. The truth is somewhere in the middle. Arrays should be indexed starSng from 0.5 Post Hoc Ergo Propter Hoc @ Correla6on implies causa6on @ “A_er this, therefore because of this” Naturalis6c Fallacy @ Inferring ought from is @ Example: Women should marry and have children, because that is their role in society. Our ancestors ate meat, so we should be carnivores. If I don’t make this technology, someone will. Name that fallacy! @ T-Rex is a preHy sweet dude, because he’s always so friggin’ awesome! @ How long did you plan to cheat on your exam? @ Either you’re with us or you are with the terrorists. @ GMOs should be banned, because they are unnatural. False Analogy @ A faulty analogy is used to make an argument @ Examples: An MP3 is like an album. Copying it is stealing! Azodicarbonamide is used in yoga mats. You wouldn’t eat a yoga mat! Special Pleading @ Making an excep6on to a rule with no jus6fica6on @ Example: I don’t have to stop for traffic lights, because I’m a veteran. You can’t detect my psychic powers because you don’t believe in them. No True Scotsman @ A generaliza6on is only true because excep6ons are ignored There are no American terrorists, because no true American would be a terrorist. Slippery Slope @ Arguing that one event must inevitably follow from another without jus6fica6on @ Examples: Allowing the NSA to spy on us will lead to a fascist dictatorship. If we legalize pot, we’ll eventually legalize heroine and crack, too. Gene6c Fallacy @ Conclusion based on the origin of an idea @ Examples Linux is the best operaSng system, because Linus Torvalds is a genius. Rocket technology started with the V-2 rocket. We should not use it. Don’t say The Pledge of Allegiance. It was wriHen by a socialist. Texas Sharpshooter Fallacy @ Inferring conclusions by pa:ern mining data @ Count “hits” and ignore “misses” @ Example: Nostradomus predicted 9/11! Five and forty degrees, the sky shall burn To the great new city shall the fire draw nigh. Composi6on/Division Fallacy @ Composi6on: arguing that the whole has the a:ributes of its parts This laptop is the best. It has the best processor, RAM, and hard drive. @ Division: arguing that the parts have a:ributes of the whole I can eat table salt, so it is safe to eat sodium. Name that fallacy! @ I shouldn’t be given a DUI, because I can hold my liquor. @ If we pardon this criminal, nobody will respect the law anymore. @ People who drink coffee every morning are as dangerous as heroine addicts. @ If a movie wins best screenplay, director and cinematography, it should win best picture. COGNITIVE BIASES Confirma6on Bias @ We search for, interpret and recall informa6on that confirms our beliefs and ignore the rest. Just-World Hypothesis @ We are biased to believe that what happens to a person was caused by their ac6ons. Fundamental A:ribu6on Error @ We tend to explain other people’s behavior by their internal a:ributes while ignoring external factors. Actor-Observer Asymmetry @ Evalua6ng our own behavior, we a:ribute it our situa6on. @ Evalua6ng other’s behavior, we a:ribute it to their personality. Self-Serving Bias @ We accept posi6ve feedback as deserved. @ We reject nega6ve feedback as invalid. Belief Bias @ We are biased to judge the strength of an argument by our belief in conclusion, ignoring the support Hindsight Bias @ Bias to believe, a_er an event has occurred, that it was the obvious outcome. Resources @ bookohadarguments.com @ yourlogicalfallacyis.com For me, it is far beHer to grasp the Universe as it really is than to persist in delusion, however saSsfying and reassuring. -Carl Sagan --------------------------------------------------------------------------------------------------------------- W6 Review @ Non sequitur @ Appeal to novelty @ Fallacy fallacy @ Poisoning the well @ Tu quouqe @ Equivoca<on @ Argument from ignorance @ Complex ques<on @ Begging the ques<on @ Post hoc propter hoc @ Naturalis<c fallacy @ Special pleading @ Gene<c fallacy @ Composi<on/Division @ Texas sharpshooter CS210: Privacy CS210 Spring 2015 Week 5 What is it? @ Conceptual muddle – A space that can be invaded? – A possession that can be lost? – A right that can be violated? Three Meanings @ Accessibility Privacy (1800’s) – Freedom from unwarranted intrusion – Physical access to your person – Fourth Amendment (search and seizure) @ Decisional Privacy (1900’s) – Freedom from interference in personal affairs – Personal choices, plans, and decisions are yours – First Amendment, Griswold v. Connec<cut, Roe vs. Wade Three Meanings @ Informa<onal Privacy (present) – Control over flow of personal informa<on – How can your informa<on be gathered, stored, mined, combined, exchanged? – Legal decisions ongoing (policy vacuum) Moor’s Account An individual [has] privacy in a situa6on with regard to others if and only if in that situa6on the individual is protected from intrusion, interference, and informa6on access by others. -James Moor Moor’s Account @ descrip6ve privacy – privacy protected by physical means – descrip<ve privacy can be lost @ norma6ve privacy – privacy protected by policies (conven<on, law) – norma<ve privacy can be violated Nissenbaum’s Account @ Privacy as “contextual integrity” – Norms depend on context (e.g. school/family) @ Norms of appropriateness – Should informa<on be gathered/divulged? @ Norms of distribu<on – Should informa<on be shared? – Transfers data to a new context @ Viola<ng norms results in a breach Importance @ Instrumental value - means to an end – Important for trust and friendship – Important for free expression and thought @ Intrinsic value - value in and of itself – Required for trust, friendship, free thought, etc. – Expression of security (Moor) @ Individual vs. social value – Required for democracy, innova<on Novel Issues? @ amount of informa<on collected @ speed informa<on can be transmibed @ dura6on of informa<on stored @ kind of informa<on stored @ data can be merged, matched, and mined Gathering @ dataveillance - surveillance and data recording – Internet cookies, search history, emails, IP address – RFID – GPS, WiFi, cell calls, text messages – Social interac<ons – Credit history, medical history @ Techniques used by companies and governments – If company has it, legal for NSA/CIA to collect Exchanging @ Data can be merged – integra<ng informa<on into a composite @ Data can be matched – Using unique iden<fiers to search mul<ple government databases to classify a person @ Violate contextual integrity Mining @ data mining indirectly gathers personal informa<on through paberns @ Difficult to regulate – Paberns are implicit in the data – Data is typically nonconfiden6al – Data is not necessarily exchanged Personal Informa<on @ Personal iden<fying informa<on (PII) - informa<on used to uniquely iden<fy a person @ Nonpublic personal informa<on (NPI) - confiden<al and private informa<on about a person @ Public personal informa<on (PPI) - public informa<on about a person PROTECTION Informed Consent @ Informed consent - user understands and agrees to how the data is used @ Current uses of informa<on are opaque to user – Do you read TOS? @ Ac<ng on presumed consent – opt-in is the standard default Privacy-Enhancing Technology (PET) @ Encryp<on services – PGP, Watsapp, iMessage, TextSecure, OTR – SSL/TLS @ Anonymizing tools – tor, proxies – Ghostery, Stealthy Policies @ Self-Regula<on – TRUSTe @ US Laws – Privacy Act, FERPA (1974!) and HIPAA (1996) @ European Laws – EU Direc<ve 95/46/EC (1995) – Regulates processing and flow of data – Right to be forgoben There is no man so good that if he placed all his ac6ons and thoughts under the scru6ny of the laws, he would not deserve hanging ten 6mes in his life. - Michel de Montaigne ---------------------------------------------------------------------------------------------------------------- W7 Review @ Accessibility privacy @ Decisional privacy @ Informa7onal privacy @ Descrip7ve vs. norma7ve privacy @ Contextual integrity @ Instrumental vs. intrinsic value @ Norms of appropriateness vs. distribu7on @ Merging vs. matching @ PII, NPI, PPI @ Informed consent @ PET @ FERPA, HIPAA, EU 95/46/EC CS210: Security and Crime CS210 Spring 2015 Week 7 Cybersecurity @ Protec7ng uses of cybertechnology @ Objec7ves: CIA triangle – Confiden7ally – Integrity – Accessibility @ Addi7onal objec7ves – Authen7city – Accountability Categories @ Three categories based on vulnerabili*es to different assets @ Data security - proprietary and sensi*ve data @ System security - hardware and soZware – Threats: malicious code (viruses, worms, malware) @ Network security - private and public networks, wireless and wired Risk Analysis @ An expecta7on of loss, expressed as a probability @ Quan7fy how likely it is an adversary will exploit a vulnerability @ de-perimeterized - security spans the boundaries of mul7ple par7es @ problem of many hands - difficult to decide who is responsible Security and Privacy @ Compa7ble: – Security protect communica7ons – Privacy prevents unauthorized access @ Incompa7ble: – Security prevents freedom of access – Privacy helps criminals avoid prosecu7on Hackers I. Access to computers should be unlimited II. All informa7on should be free III. Mistrust authority IV. Hackers should be judged by their skill V. You can create art and beauty on a computer VI. Computers can change your life for the beber Hack7vism @ Electronic poli7cal ac7vism @ A form of civil disobedience – No damage to persons or property – Nonviolent – Not for personal profit – Ethical mo7va7on – Willingness to accept personal responsibility Hacker Ethic 1. Informa7on should be free 2. Hackers provide society with a useful service 3. Ac7vi7es in cyberspace are virtual Ethical Hacker @ Hacking systems with – permission – exper*se – document vulnerabili*es @ Called “white hats” @ Also “pentesters” @ “Hacking back” is ethically ques7onable Cybercrime @ Crime which is carried out exclusively using cybertechnology and takes place en7rely within cyberspace @ Cyberpiracy - unauthorized reproduc7on or distribu7on of proprietary informa7on @ Cybertrespass - unauthorized access to computer systems @ Cybervandalism- unauthorized disrup7on of service or destruc7on of data Cyber-related crime @ Conven7onal crime exacerbated by cybertech @ Cyberstalking @ Harassment @ Drug trafficking (e.g. Silk Road) @ Iden7ty theZ @ Distribu7ng child pornography @ Fraud @ Phishing @ Spam @ Libel/Slander @ Counterfei7ng @ Industrial espionage Cyberterrorism @ Poli7cally mo7vated hacking intended to cause grave harm @ Grave harm - loss of life, bodily harm, or severe economic loss @ Dis7nct from cyberharassment and hack7vism? Informa7on Warfare @ Na7on states engaged in hacking @ Malware and cyberabacks to mislead and disrupt cri7cal infrastructure of adversary @ Advanced Persistent Threat – mul7stage, persistent computer hack targe7ng one en7ty (government, company) Law and Cybercrime @ Problem of jurisdic7on - cybercrime easily crosses mul7ple borders @ Laws being established through trea7es and trade agreements @ G8 summit in 2000, Council of Europe draZed “COE Conven7on on Cybercrime” @ Trans-Pacific Partnership (TPP) Intellectual Property Rights Chapter released by Wikileaks You can be secure even though you don’t feel secure, and you can feel secure even though you’re not really secure. - Bruce Schneier


